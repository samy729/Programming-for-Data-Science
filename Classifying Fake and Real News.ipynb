{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe 'data' is created\n",
    "data = pd.read_csv('fake_or_real_news.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6335 entries, 0 to 6334\n",
      "Data columns (total 4 columns):\n",
      "Unnamed: 0    6335 non-null int64\n",
      "title         6335 non-null object\n",
      "text          6335 non-null object\n",
      "label         6335 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 198.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Concise summary about the dataframe\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    3171\n",
       "FAKE    3164\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of real and fake news\n",
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                         title  \\\n",
       "0  8476  You Can Smell Hillary’s Fear   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming column name 'Unnamed: 0' to 'ID'\n",
    "data = data.rename({'Unnamed: 0': 'ID'}, axis='columns')\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "ID                                                         \n",
       "8476                        You Can Smell Hillary’s Fear   \n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "3608         Kerry to go to Paris in gesture of sympathy   \n",
       "10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "875     The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                    text label  \n",
       "ID                                                              \n",
       "8476   Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "10294  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "3608   U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "10142  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "875    It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.set_index('ID')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use only the 'text' column to predict news category(FAKE or REAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "8476     Daniel Greenfield, a Shillman Journalism Fello...\n",
       "10294    Google Pinterest Digg Linkedin Reddit Stumbleu...\n",
       "3608     U.S. Secretary of State John F. Kerry said Mon...\n",
       "10142    — Kaydee King (@KaydeeKing) November 9, 2016 T...\n",
       "875      It's primary day in New York and front-runners...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.text\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "8476     FAKE\n",
       "10294    FAKE\n",
       "3608     REAL\n",
       "10142    FAKE\n",
       "875      REAL\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target Variable\n",
    "y = data.label\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since, MultinomialNB Classifier is tuned to work with numbers, we will use CountVectorizer function to convert text to a matrix of token counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vec = CountVectorizer(stop_words='english')\n",
    "count_train = count_vec.fit_transform(X_train)\n",
    "count_test = count_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.int64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': None, 'min_df': 1, 'ngram_range': (1, 1), 'preprocessor': None, 'stop_words': 'english', 'strip_accents': None, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'vocabulary': None}\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer paramaters\n",
    "print(count_vec.get_params(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'have', 'ie', 'due', 'else', 'often', 'seemed', 'could', 'fifty', 'hasnt', 'hence', 'here', 'least', 'formerly', 'ten', 'de', 'sometimes', 'may', 'no', 'they', 'beside', 'system', 'before', 'him', 'many', 'the', 'those', 'twenty', 'whereby', 'would', 'your', 'even', 'always', 'sometime', 'empty', 'down', 'yours', 'within', 'their', 'get', 'sixty', 'more', 'noone', 'ltd', 'becomes', 'below', 'became', 'too', 'whence', 'be', 'me', 'however', 'wherein', 'almost', 'an', 'namely', 'wherever', 'etc', 'above', 'none', 'own', 'somewhere', 'whoever', 'thereupon', 'whole', 'anyway', 'everywhere', 'after', 'throughout', 'last', 'toward', 'a', 'amongst', 'while', 'by', 'beyond', 'two', 'only', 'either', 'or', 'eleven', 'next', 'herself', 'one', 'back', 'hereafter', 'also', 'every', 'except', 'mill', 'thereafter', 'nine', 'must', 'ours', 'mostly', 'describe', 'front', 'whom', 'against', 'although', 'this', 'few', 'same', 'much', 'elsewhere', 'together', 'behind', 'for', 'less', 'any', 'couldnt', 'over', 'how', 'serious', 'nothing', 'do', 'and', 'seeming', 'otherwise', 'should', 'there', 'six', 'thick', 'third', 'top', 'take', 'bottom', 'see', 'myself', 'each', 'towards', 'someone', 'whatever', 'therefore', 'still', 'amount', 'we', 'mine', 'yourself', 'hereupon', 'former', 're', 'first', 'thin', 'whither', 'part', 'at', 'themselves', 'name', 'being', 'our', 'whereafter', 'among', 'perhaps', 'if', 'both', 'ever', 'itself', 'becoming', 'anyhow', 'now', 'when', 'again', 'put', 'yourselves', 'through', 'twelve', 'indeed', 'is', 'thereby', 'whose', 'neither', 'inc', 'whereas', 'with', 'during', 'to', 'its', 'cant', 'interest', 'us', 'from', 'around', 'was', 'his', 'why', 'them', 'so', 'not', 'eight', 'on', 'very', 'where', 'under', 'of', 'anything', 'my', 'but', 'nevertheless', 'nobody', 'once', 'yet', 'you', 'call', 'off', 'something', 'seems', 'cannot', 'beforehand', 'full', 'he', 'others', 'show', 'hers', 'it', 'sincere', 'latter', 'were', 'amoungst', 'such', 'out', 'am', 'find', 'rather', 'done', 'had', 'she', 'because', 'without', 'what', 'fill', 'into', 'along', 'might', 'move', 'seem', 'thru', 'made', 'latterly', 'meanwhile', 'himself', 'everyone', 'other', 'these', 'via', 'as', 'keep', 'well', 'four', 'up', 'enough', 'whenever', 'please', 'most', 'i', 'become', 'until', 'fire', 'co', 'alone', 'everything', 'hundred', 'in', 'though', 'thus', 'who', 'found', 'further', 'across', 'bill', 'about', 'afterwards', 'anywhere', 'side', 'herein', 'thence', 'five', 'nor', 'some', 'nowhere', 'several', 'upon', 'her', 'all', 'already', 'then', 'whereupon', 'whether', 'cry', 'onto', 'never', 'three', 'per', 'that', 'eg', 'are', 'give', 'than', 'will', 'which', 'between', 'can', 'con', 'detail', 'fifteen', 'has', 'forty', 'hereby', 'since', 'go', 'anyone', 'besides', 'ourselves', 'another', 'moreover', 'been', 'somehow', 'un', 'therein'})\n"
     ]
    }
   ],
   "source": [
    "# Stop words in the traning set\n",
    "print(count_vec.get_stop_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '000000031', '00000031', '00006', '0001pt', '0002', '000billion', '000ft', '000x', '001', '002', '003', '004', '005', '006', '00684', '006s', '007', '007s', '008', '008s', '009', '0099', '00am', '00p', '00pm', '01', '011']\n"
     ]
    }
   ],
   "source": [
    "# First 30 features names mapped from the feature integer\n",
    "print(count_vec.get_feature_names()[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59647"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of featrues in count_vectorizer\n",
    "len(count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>000000031</th>\n",
       "      <th>00000031</th>\n",
       "      <th>00006</th>\n",
       "      <th>0001pt</th>\n",
       "      <th>0002</th>\n",
       "      <th>000billion</th>\n",
       "      <th>000ft</th>\n",
       "      <th>...</th>\n",
       "      <th>حلب</th>\n",
       "      <th>عربي</th>\n",
       "      <th>عن</th>\n",
       "      <th>لم</th>\n",
       "      <th>ما</th>\n",
       "      <th>محاولات</th>\n",
       "      <th>من</th>\n",
       "      <th>هذا</th>\n",
       "      <th>والمرضى</th>\n",
       "      <th>ยงade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59647 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  000000031  00000031  00006  0001pt  0002  000billion  000ft  \\\n",
       "0   0    0     0          0         0      0       0     0           0      0   \n",
       "1   0    1     0          0         0      0       0     0           0      0   \n",
       "2   0    1     0          0         0      0       0     0           0      0   \n",
       "3   0    0     0          0         0      0       0     0           0      0   \n",
       "4   0    0     0          0         0      0       0     0           0      0   \n",
       "\n",
       "   ...    حلب  عربي  عن  لم  ما  محاولات  من  هذا  والمرضى  ยงade  \n",
       "0  ...      0     0   0   0   0        0   0    0        0      0  \n",
       "1  ...      0     0   0   0   0        0   0    0        0      0  \n",
       "2  ...      0     0   0   0   0        0   0    0        0      0  \n",
       "3  ...      0     0   0   0   0        0   0    0        0      0  \n",
       "4  ...      0     0   0   0   0        0   0    0        0      0  \n",
       "\n",
       "[5 rows x 59647 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe 'count_X_train' with features names along with their count\n",
    "count_X_train = pd.DataFrame(count_train.A, columns = count_vec.get_feature_names())\n",
    "count_X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Naive Bayes Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB() \n",
    "clf.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.8819\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy with default MutinomialNB parameter (i.e at alpha = 1)  is 88.19%. Let's try to find best parameter value to get a better accuracy using GridSearchCV function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid={'alpha':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}\n",
    "grid_search = GridSearchCV(clf, param_grid, cv = 5)\n",
    "grid_search.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'alpha': 0.1}\n",
      "Best score 0.90\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.2f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building classifer with best parameter (alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=0.1) \n",
    "clf.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.8870\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(count_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that accuracy is improved from 88.19% to 88.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[653 114]\n",
      " [ 65 752]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.91      0.85      0.88       767\n",
      "       REAL       0.87      0.92      0.89       817\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred, labels=['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model has precision of 91% for predicting Fake News which seems to be good enough for a spam classifer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 words for Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-16.18204997023321, '0001pt'),\n",
       " (-16.18204997023321, '0002'),\n",
       " (-16.18204997023321, '000billion'),\n",
       " (-16.18204997023321, '005'),\n",
       " (-16.18204997023321, '00684'),\n",
       " (-16.18204997023321, '006s'),\n",
       " (-16.18204997023321, '007'),\n",
       " (-16.18204997023321, '007s'),\n",
       " (-16.18204997023321, '008s'),\n",
       " (-16.18204997023321, '0099'),\n",
       " (-16.18204997023321, '00am'),\n",
       " (-16.18204997023321, '00p'),\n",
       " (-16.18204997023321, '00pm'),\n",
       " (-16.18204997023321, '013c2812c9'),\n",
       " (-16.18204997023321, '01am'),\n",
       " (-16.18204997023321, '020'),\n",
       " (-16.18204997023321, '02714'),\n",
       " (-16.18204997023321, '02870'),\n",
       " (-16.18204997023321, '02welcome'),\n",
       " (-16.18204997023321, '031'),\n",
       " (-16.18204997023321, '032'),\n",
       " (-16.18204997023321, '033'),\n",
       " (-16.18204997023321, '03747'),\n",
       " (-16.18204997023321, '039'),\n",
       " (-16.18204997023321, '0400'),\n",
       " (-16.18204997023321, '049'),\n",
       " (-16.18204997023321, '04pm'),\n",
       " (-16.18204997023321, '0509245d29'),\n",
       " (-16.18204997023321, '052'),\n",
       " (-16.18204997023321, '053')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = count_vec.get_feature_names()\n",
    "sorted(zip(clf.coef_[0], features))[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 words for Real News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-4.437211518097527, 'said'),\n",
       " (-4.54327630289812, 'trump'),\n",
       " (-4.897393670119733, 'clinton'),\n",
       " (-5.43632735165234, 'state'),\n",
       " (-5.444111006439407, 'president'),\n",
       " (-5.455023141954477, 'people'),\n",
       " (-5.466943549766896, 'obama'),\n",
       " (-5.52359133474522, 'new'),\n",
       " (-5.554376947352951, 'campaign'),\n",
       " (-5.674219128812631, 'republican'),\n",
       " (-5.775940351281779, 'party'),\n",
       " (-5.910072545713812, 'time'),\n",
       " (-5.923303475816235, 'states'),\n",
       " (-5.937067103593539, 'just'),\n",
       " (-5.940626966382516, 'like'),\n",
       " (-5.961163788457368, 'sanders'),\n",
       " (-5.990717858446995, 'house'),\n",
       " (-6.035184959552062, 'percent'),\n",
       " (-6.075580758206824, 'political'),\n",
       " (-6.119381553344769, 'voters'),\n",
       " (-6.120234759317777, 'year'),\n",
       " (-6.1245117428701565, 'presidential'),\n",
       " (-6.128376730933197, 'democratic'),\n",
       " (-6.129668387015645, 'republicans'),\n",
       " (-6.17957718101266, 'white'),\n",
       " (-6.190505753876798, 'cruz'),\n",
       " (-6.224026885049067, 'told'),\n",
       " (-6.248955072944423, 'going'),\n",
       " (-6.2611646405206605, 'say'),\n",
       " (-6.264117253265585, 'years')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(clf.coef_[0], features), reverse=True)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
